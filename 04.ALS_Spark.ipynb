{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendación por filtrado colabarativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya sabemos, las recomendaciones por filtrado colaborativo, usan la propia información que los usuarios nos deja al interactuar con nuestros items. Pordemos ver la idea en el siguiente gif:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/450px-Collaborative_filtering.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto que dentro de las técnicas de filtrado colaborativo podemos distinguir entre las \"basado en memoria\" y las basdas en factorización de matrices.\n",
    "\n",
    "En este notebook vamos a ver un ejemplo con Spark (pyspark) y este segundo tipo de sistemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/memory-model-cf.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello nos basamos en el siguiente [guión](https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html) (ya han dado de baja la web pero podemos usar el siguiente [link](https://web.archive.org/web/20160316113725/https://databricks-training.s3.amazonaws.com/movie-recommendation-with-mllib.html)) del Spark Summit 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Antes de empezar\n",
    "\n",
    "Necesitamos descargar los datos en la carpeta `../datos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /datos: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA:** Si no existen las carpetas `ml-1m` y `tag-genome` usamos el script `descargar_movilens.sh` para descargarlos.\n",
    "\n",
    "## Los datos\n",
    "\n",
    "En la carpeta `ml-1m`  que contiene: \n",
    "\n",
    "> Stable benchmark dataset. 1 million ratings from 6000 users on 4000 movies. Released 2/2003.\n",
    "\n",
    "Hemos descargado estos datos que son pequeños para hacer las pruebas, pero el sistema que vamos a utilizar con Spark es distribuido y lo podríamos hacer sobre un cluster con el mismo código para datos más grandes.\n",
    "\n",
    "Los datos que incluye MovieLens son:\n",
    "\n",
    "* `movies.dat`: Incluye el catálogo de películas separado por `::` cada campo.\n",
    "* `ratings.dat`: Incluye los ratings entre usuarios y películas en este caso la puntuación (de 1 a 5) que han dado a esa película. Este archivo es nuestra matriz $M_{(n, p)}$ .\n",
    "* `users.dat`: Incluye información de los usuarios pero en nuestro ejercicio no vamos a utilizar este archivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1::Toy Story (1995)::Animation|Children's|Comedy\r\n",
      "2::Jumanji (1995)::Adventure|Children's|Fantasy\r\n",
      "3::Grumpier Old Men (1995)::Comedy|Romance\r\n",
      "4::Waiting to Exhale (1995)::Comedy|Drama\r\n",
      "5::Father of the Bride Part II (1995)::Comedy\r\n",
      "6::Heat (1995)::Action|Crime|Thriller\r\n",
      "7::Sabrina (1995)::Comedy|Romance\r\n",
      "8::Tom and Huck (1995)::Adventure|Children's\r\n",
      "9::Sudden Death (1995)::Action\r\n",
      "10::GoldenEye (1995)::Action|Adventure|Thriller\r\n",
      "text: Unable to write to output stream.\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -text /datos/ml-1m/movies.dat | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1::1193::5::978300760\r\n",
      "1::661::3::978302109\r\n",
      "1::914::3::978301968\r\n",
      "1::3408::4::978300275\r\n",
      "1::2355::5::978824291\r\n",
      "1::1197::3::978302268\r\n",
      "1::1287::5::978302039\r\n",
      "1::2804::5::978300719\r\n",
      "1::594::4::978302268\r\n",
      "1::919::4::978301368\r\n",
      "text: Unable to write to output stream.\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -text /datos/ml-1m/ratings.dat | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incluirnos en el recomendador\n",
    "\n",
    "Una de las características importantes de los sitemas de recomendación basados en factorización de matrices. Es que desde el entrenamiento del modelo tendremos que incluir a todos los usuarios a los que vamos a querer recomendar. Al contrario que otros modelos de *machine learning* donde una vez entrenado el modelo podemos predecir a nuevos usuarios.\n",
    "\n",
    "Para ello vamos a incluir nuestras preferencias como un nuevo usuario y después veremos las recomendaciones que obtenemos para nosotros mismos.\n",
    "\n",
    "¿Cómo hacemos esto?\n",
    "\n",
    "El siguiente script en python `spark_als/bin/rateMovies` sirve para generar nuestras recomendaciones.\n",
    "\n",
    "Una vez ejecutado se crearán nuestros ratings en el archivo `personalRatings.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0::1::4::1583788918\n",
      "0::780::4::1583788918\n",
      "0::1210::5::1583788918\n",
      "0::648::5::1583788918\n",
      "0::344::1::1583788918\n",
      "0::165::5::1583788918\n",
      "0::153::4::1583788918\n",
      "0::597::1::1583788918\n",
      "0::1580::3::1583788918\n",
      "0::231::1::1583788918\n"
     ]
    }
   ],
   "source": [
    "!cat personalRatings.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark y MLlib\n",
    "\n",
    "Para nuestro recomendador vamos a usar Spark y la librería MLlib que incluye el algoritmo ALS:    \n",
    "\n",
    "&nbsp;<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/matrix_factorization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero de todo comprobamos que tenemos creado el `SparkContext`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "# Cargamos las funciones definidas en el archivo funciones_auxiliares.py\n",
    "from funciones_auxiliares import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "\n",
    "    SparkConf()\n",
    "    .setAppName(u\"Sistemas de Recomendación\")\n",
    "    .set(\"spark.executor.memory\", \"4g\")\n",
    "    .set(\"spark.executor.cores\", \"2\")\n",
    "    .set(\"spark.default.parallelism\", \"800\")\n",
    "    .set(\"spark.sql.shuffle.partitions\", \"800\")\n",
    "    .set(\"spark.submit.pyFiles\", \"funciones_auxiliares.py\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.io.FileNotFoundException: File file:/C:/Users/jhern/Jupyter%20Notebooks/ML%20II/Recommender%20Systems/04.%20Filtrado%20Colaborativo/funciones_auxiliares.py does not exist\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)\r\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)\r\n\tat org.apache.spark.SparkContext.addFile(SparkContext.scala:1544)\r\n\tat org.apache.spark.SparkContext.addFile(SparkContext.scala:1508)\r\n\tat org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:462)\r\n\tat org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:462)\r\n\tat scala.collection.immutable.List.foreach(List.scala:392)\r\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:462)\r\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat java.lang.reflect.Constructor.newInstance(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:238)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ad173fde2190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mSparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0menableHiveSupport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    171\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                     \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m                     \u001b[1;31m# This SparkContext may be an existing one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[1;32m--> 136\u001b[1;33m                           conf, jsc, profiler_cls)\n\u001b[0m\u001b[0;32m    137\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[1;31m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_do_init\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# Create the Java SparkContext through Py4J\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjsc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[1;31m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_initialize_context\u001b[1;34m(self, jconf)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[0mInitialize\u001b[0m \u001b[0mSparkContext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mto\u001b[0m \u001b[0mallow\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mspecific\u001b[0m \u001b[0minitialization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \"\"\"\n\u001b[1;32m--> 306\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJavaSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1523\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1524\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1525\u001b[1;33m             answer, self._gateway_client, None, self._fqn)\n\u001b[0m\u001b[0;32m   1526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1527\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.io.FileNotFoundException: File file:/C:/Users/jhern/Jupyter%20Notebooks/ML%20II/Recommender%20Systems/04.%20Filtrado%20Colaborativo/funciones_auxiliares.py does not exist\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)\r\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)\r\n\tat org.apache.spark.SparkContext.addFile(SparkContext.scala:1544)\r\n\tat org.apache.spark.SparkContext.addFile(SparkContext.scala:1508)\r\n\tat org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:462)\r\n\tat org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:462)\r\n\tat scala.collection.immutable.List.foreach(List.scala:392)\r\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:462)\r\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)\r\n\tat java.lang.reflect.Constructor.newInstance(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:238)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "\n",
    "    SparkSession.builder\n",
    "    .config(conf=conf)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos la función `loadRatings` para cargar nuestros ratings personales: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la carpeta donde se encuentras nuestros archivos y usamos la función `parseRating` de manera distribuida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_hdfs = '/datos/ml-1m/ratings.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Delimiter cannot be more than one character: ::'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark.read.options(header=False, sep=\"::\").csv(ratings_hdfs).show()\n",
    "except Exception as e: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.sparkContext.textFile(ratings_hdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1::1193::5::978300760',\n",
       " '1::661::3::978302109',\n",
       " '1::914::3::978301968',\n",
       " '1::3408::4::978300275']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = lines.map(lambda row: row.split(\"::\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '1193', '5', '978300760'],\n",
       " ['1', '661', '3', '978302109'],\n",
       " ['1', '914', '3', '978301968'],\n",
       " ['1', '3408', '4', '978300275']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsRDD = (\n",
    "    parts\n",
    "    .map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]), rating=float(p[2]), timestamp=int(p[3])))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieId=1193, rating=5.0, timestamp=978300760, userId=1),\n",
       " Row(movieId=661, rating=3.0, timestamp=978302109, userId=1),\n",
       " Row(movieId=914, rating=3.0, timestamp=978301968, userId=1),\n",
       " Row(movieId=3408, rating=4.0, timestamp=978300275, userId=1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsRDD.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratingsRDD.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+------+\n",
      "|movieId|rating|timestamp|userId|\n",
      "+-------+------+---------+------+\n",
      "|   1193|   5.0|978300760|     1|\n",
      "|    661|   3.0|978302109|     1|\n",
      "|    914|   3.0|978301968|     1|\n",
      "|   3408|   4.0|978300275|     1|\n",
      "+-------+------+---------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegamos ahora nuestros ratings al mismo `DF`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRatings = pd.read_csv(\n",
    "\n",
    "    \"personalRatings.txt\",\n",
    "    sep=\"::\",\n",
    "    names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"],\n",
    "    engine='python'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1583788918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>780</td>\n",
       "      <td>4</td>\n",
       "      <td>1583788918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1210</td>\n",
       "      <td>5</td>\n",
       "      <td>1583788918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>648</td>\n",
       "      <td>5</td>\n",
       "      <td>1583788918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>1</td>\n",
       "      <td>1583788918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>5</td>\n",
       "      <td>1583788918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>4</td>\n",
       "      <td>1583788918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>1</td>\n",
       "      <td>1583788918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1580</td>\n",
       "      <td>3</td>\n",
       "      <td>1583788918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>1583788918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       0        1       4  1583788918\n",
       "1       0      780       4  1583788918\n",
       "2       0     1210       5  1583788918\n",
       "3       0      648       5  1583788918\n",
       "4       0      344       1  1583788918\n",
       "5       0      165       5  1583788918\n",
       "6       0      153       4  1583788918\n",
       "7       0      597       1  1583788918\n",
       "8       0     1580       3  1583788918\n",
       "9       0      231       1  1583788918"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = (\n",
    "\n",
    "    ratings\n",
    "    .union(\n",
    "        spark.createDataFrame(myRatings).select(ratings.columns)\n",
    "    )\n",
    "\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_hdfs = '/datos/ml-1m/movies.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = (\n",
    "\n",
    "    spark.sparkContext\n",
    "    .textFile(movies_hdfs)\n",
    "    .map(lambda x: x.split(\"::\"))\n",
    "    .map(lambda x: Row(movieId=x[0], movieTitle=x[1], genres=x[2]))\n",
    "    .toDF()\n",
    "\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conteos = (\n",
    "\n",
    "    ratings\n",
    "    .select(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.countDistinct('userId').alias('userId'),\n",
    "        F.countDistinct('movieId').alias('movieId')\n",
    "    )\n",
    "\n",
    ").first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados ambos archivos vamos a contar el número de películas, usuarios y ratings que tenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1000219 ratings from 6041 users on 3706 movies.\n"
     ]
    }
   ],
   "source": [
    "print(\"Got %d ratings from %d users on %d movies.\" % conteos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego siguiendo nuestra notación tenemos que:\n",
    "\n",
    "* $n=6041$\n",
    "* $p=3706$\n",
    "\n",
    "Así que la matriz $M$ tiene un tamaño de $6041\\cdot3706=22387946$ pero solo tenemos información de $1000218$, es decir un 4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "\n",
    "    maxIter=5, \n",
    "    regParam=0.01, \n",
    "    userCol=\"userId\", \n",
    "    itemCol=\"movieId\", \n",
    "    ratingCol=\"rating\",\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALS_47a8aa4465b78508473c"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      " |-- prediction: float (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+------+----------+\n",
      "|movieId|rating| timestamp|userId|prediction|\n",
      "+-------+------+----------+------+----------+\n",
      "|   1580|   4.0| 963028136|  4777| 3.7535176|\n",
      "|   1580|   1.0| 958306790|  5758| 2.7779112|\n",
      "|   1580|   5.0| 958254615|  5759| 3.7450058|\n",
      "|   1580|   4.0| 977085423|   182| 3.7428849|\n",
      "|   1580|   4.0| 974330478|  2380| 3.4430072|\n",
      "|   1580|   3.0| 959097998|  5621|  2.643875|\n",
      "|   1580|   3.0| 977176300|   168| 3.5407069|\n",
      "|   1580|   3.0| 975883616|  1952| 3.0650675|\n",
      "|   1580|   5.0| 962855202|  5167| 3.6679313|\n",
      "|   1580|   3.0| 977501276|   117|  3.779159|\n",
      "|   1580|   4.0| 973218090|  2743| 4.0912867|\n",
      "|   1580|   4.0| 972526890|  2845|  4.117525|\n",
      "|   1580|   4.0| 970125552|  3056|  3.797142|\n",
      "|   1580|   4.0| 966303578|  3931| 3.8660393|\n",
      "|   1580|   4.0| 965352384|  4130| 3.8831992|\n",
      "|   1580|   4.0| 959290430|  5580| 3.6374292|\n",
      "|   1580|   5.0| 974559452|  2279| 3.7993147|\n",
      "|   1580|   4.0|1006656956|  2926| 3.5773067|\n",
      "|   1580|   4.0| 975600806|   687| 3.6202857|\n",
      "|   1580|   5.0| 975097935|   987| 4.1406813|\n",
      "+-------+------+----------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.7713123288648368\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- movieId: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|  3997|[[2545, 9.269251]...|\n",
      "|  2122|[[572, 6.5878496]...|\n",
      "|  1829|[[3867, 9.124575]...|\n",
      "|  4519|[[1539, 9.595539]...|\n",
      "|  5156|[[557, 6.2800536]...|\n",
      "|  3175|[[1857, 7.107347]...|\n",
      "|  1580|[[2562, 7.295412]...|\n",
      "|  3918|[[2305, 9.726513]...|\n",
      "|  1025|[[2964, 12.635993...|\n",
      "|  2235|[[136, 8.588034],...|\n",
      "|  1483|[[2964, 9.721584]...|\n",
      "|  1990|[[1471, 9.474205]...|\n",
      "|  2580|[[2332, 9.618193]...|\n",
      "|  1721|[[2192, 7.7569265...|\n",
      "|  4161|[[2705, 5.9256997...|\n",
      "|  3179|[[681, 8.902837],...|\n",
      "|  4219|[[3944, 6.4903746...|\n",
      "|  4929|[[2209, 7.9432025...|\n",
      "|  5117|[[136, 8.072485],...|\n",
      "|  5287|[[572, 6.0133295]...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>genres</th>\n",
       "      <th>movieTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2545</td>\n",
       "      <td>0</td>\n",
       "      <td>18.208933</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Relax... It's Just Sex (1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2984</td>\n",
       "      <td>0</td>\n",
       "      <td>17.591209</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>On Any Sunday (1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1859</td>\n",
       "      <td>0</td>\n",
       "      <td>17.287172</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Taste of Cherry (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751</td>\n",
       "      <td>0</td>\n",
       "      <td>17.187618</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Careful (1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3867</td>\n",
       "      <td>0</td>\n",
       "      <td>16.293430</td>\n",
       "      <td>Drama</td>\n",
       "      <td>All the Rage (a.k.a. It's the Rage) (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2964</td>\n",
       "      <td>0</td>\n",
       "      <td>15.348584</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Julien Donkey-Boy (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2246</td>\n",
       "      <td>0</td>\n",
       "      <td>14.548626</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Stars and Bars (1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2483</td>\n",
       "      <td>0</td>\n",
       "      <td>14.534881</td>\n",
       "      <td>Comedy|Horror|Thriller</td>\n",
       "      <td>Day of the Beast, The (El D�a de la bestia) (1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3850</td>\n",
       "      <td>0</td>\n",
       "      <td>14.424432</td>\n",
       "      <td>Crime|Thriller</td>\n",
       "      <td>Whatever Happened to Aunt Alice? (1969)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2332</td>\n",
       "      <td>0</td>\n",
       "      <td>14.371967</td>\n",
       "      <td>Crime|Drama</td>\n",
       "      <td>Belly (1998)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  userId     rating                  genres  \\\n",
       "0     2545       0  18.208933                  Comedy   \n",
       "1     2984       0  17.591209             Documentary   \n",
       "2     1859       0  17.287172                   Drama   \n",
       "3      751       0  17.187618                  Comedy   \n",
       "4     3867       0  16.293430                   Drama   \n",
       "5     2964       0  15.348584                   Drama   \n",
       "6     2246       0  14.548626                  Comedy   \n",
       "7     2483       0  14.534881  Comedy|Horror|Thriller   \n",
       "8     3850       0  14.424432          Crime|Thriller   \n",
       "9     2332       0  14.371967             Crime|Drama   \n",
       "\n",
       "                                          movieTitle  \n",
       "0                      Relax... It's Just Sex (1998)  \n",
       "1                               On Any Sunday (1971)  \n",
       "2                             Taste of Cherry (1997)  \n",
       "3                                     Careful (1992)  \n",
       "4         All the Rage (a.k.a. It's the Rage) (1999)  \n",
       "5                           Julien Donkey-Boy (1999)  \n",
       "6                              Stars and Bars (1988)  \n",
       "7  Day of the Beast, The (El D�a de la bestia) (1...  \n",
       "8            Whatever Happened to Aunt Alice? (1969)  \n",
       "9                                       Belly (1998)  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "\n",
    "    userRecs\n",
    "    .filter(\"\"\" userId = 0 \"\"\")\n",
    "    .withColumn(\"recommendations\",F.explode(\"recommendations\"))\n",
    "    .withColumn(\"movieId\",F.col('recommendations')['movieId'])\n",
    "    .withColumn(\"rating\",F.col('recommendations')['rating'])\n",
    "    .drop(\"recommendations\")\n",
    "    .join(movies, 'movieId')\n",
    "    .orderBy(F.desc('rating'))\n",
    "    \n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRecs = model.recommendForAllItems(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|   1829|[[2640, 6.709895]...|\n",
      "|   3175|[[4565, 6.0995197...|\n",
      "|   3918|[[0, 6.7730665], ...|\n",
      "|   2122|[[3587, 7.0087514...|\n",
      "|   1580|[[5642, 5.815876]...|\n",
      "|   3179|[[448, 5.555192],...|\n",
      "|   1990|[[3396, 5.58051],...|\n",
      "|   2580|[[5328, 5.34707],...|\n",
      "|   1483|[[0, 10.328633], ...|\n",
      "|   1721|[[1520, 6.186659]...|\n",
      "|   1025|[[2441, 7.087336]...|\n",
      "|   2235|[[2441, 2.5812492...|\n",
      "|   1139|[[283, 5.258524],...|\n",
      "|   1322|[[1664, 7.057609]...|\n",
      "|     85|[[5328, 7.2474275...|\n",
      "|   2525|[[5642, 6.900554]...|\n",
      "|   3089|[[0, 6.6785035], ...|\n",
      "|   3220|[[2441, 2.5812492...|\n",
      "|   2443|[[2441, 9.088114]...|\n",
      "|   2923|[[2151, 10.5367],...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ratings.select(als.getUserCol()).distinct().limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|userId|\n",
      "+------+\n",
      "|  1508|\n",
      "|  1766|\n",
      "|  1776|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "userSubsetRecs = model.recommendForUserSubset(users, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|  1210|[[3245, 8.203256]...|\n",
      "|  1756|[[1471, 9.243921]...|\n",
      "|  1302|[[2569, 10.503956...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userSubsetRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- movieId: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userSubsetRecs.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de los parámetros\n",
    "\n",
    "Para decidir qué parámetros utilizar en nuestro algoritmo vamos a dividir la muestra en tres trozos:\n",
    "entrenamiento (60%), validación (20%) y test (20%). Para ello lo hacemos basado en el último dígito del `timestamp` \n",
    "(ver la función `parseRating` línea 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = ratings.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos ahora los posibles valores de nuestros parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: alpha for implicit preference (default: 1.0)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "coldStartStrategy: strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'. (default: nan)\n",
      "finalStorageLevel: StorageLevel for ALS model factors. (default: MEMORY_AND_DISK)\n",
      "implicitPrefs: whether to use implicit preference (default: False)\n",
      "intermediateStorageLevel: StorageLevel for intermediate datasets. Cannot be 'NONE'. (default: MEMORY_AND_DISK)\n",
      "itemCol: column name for item ids. Ids must be within the integer value range. (default: item)\n",
      "maxIter: max number of iterations (>= 0). (default: 10)\n",
      "nonnegative: whether to use nonnegative constraint for least squares (default: False)\n",
      "numItemBlocks: number of item blocks (default: 10)\n",
      "numUserBlocks: number of user blocks (default: 10)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "rank: rank of the factorization (default: 10)\n",
      "ratingCol: column name for ratings (default: rating)\n",
      "regParam: regularization parameter (>= 0). (default: 0.1)\n",
      "seed: random seed. (default: 7493584504910341346)\n",
      "userCol: column name for user ids. Ids must be within the integer value range. (default: user)\n"
     ]
    }
   ],
   "source": [
    "print(ALS().explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "\n",
    "    userCol=\"userId\", \n",
    "    itemCol=\"movieId\", \n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (\n",
    "\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(als.rank, [10, 100])\n",
    "    .addGrid(als.regParam, [0.01, 0.1])\n",
    "    .addGrid(als.maxIter, [5, 10])\n",
    "    .build()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(\n",
    "\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=2\n",
    "\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡Cuidado esta parte tarda mucho!**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cvModel = crossval.fit(training)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cvModel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mallado = pd.DataFrame(paramGrid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mallado.columns=[i.name for i in mallado.columns]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mallado['avgMetrics'] = cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mallado.sort_values('avgMetrics', inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mallado"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cvModel.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejercicio habitual en *machine learning* es comparar el resultado de nuestro modelo con el *baseline*. En este caso con la media de los ratings y ver si nuestro modelo es mejor y en cuanto"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "baselineRmse = (\n",
    "\n",
    "    test\n",
    "    .crossJoin(\n",
    "        F.broadcast(ratings.select(F.mean('rating').alias('media')))\n",
    "    )\n",
    "    .withColumn('rmse', (F.col('media') - F.col('rating')) ** 2 )\n",
    "    .select(F.mean('rmse').alias('rmse'))\n",
    "    .first()['rmse']\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "testRmse = evaluator.evaluate(cvModel.bestModel.transform(test))\n",
    "improvement = (baselineRmse - testRmse) / baselineRmse * 100\n",
    "print(\"The best model improves the baseline by %.2f\" % (improvement) + \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo final\n",
    "Terminamos entrenando el modelo final con todos los datos y los parámetros que hemos elegido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalModel = ALS(\n",
    "\n",
    "    regParam=0.01, #mallado.iloc[0]['regParam'],\n",
    "    maxIter=20, #mallado.iloc[0]['maxIter'],\n",
    "    rank=100, #mallado.iloc[0]['rank'],\n",
    "    userCol=\"userId\", \n",
    "    itemCol=\"movieId\", \n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\"\n",
    "\n",
    ").fit(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.363889289559987\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(finalModel.transform(ratings))\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver nuestras recomendaciones\n",
    "\n",
    "Vamos a recuperar las recomendaciones según los ratings que pusimos al principio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRecs = finalModel.recommendForAllUsers(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Mejor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = (\n",
    "\n",
    "    userRecs\n",
    "    .filter(\"\"\" userId = 0 \"\"\")\n",
    "    .withColumn(\"recommendations\", F.explode(\"recommendations\"))\n",
    "    .withColumn(\"movieId\", F.col('recommendations')['movieId'])\n",
    "    .withColumn(\"rating\", F.col('recommendations')['rating'])\n",
    "    .drop(\"recommendations\")\n",
    "    .join(ratings, ['userId', 'movieId'], 'left_anti')\n",
    "    .join(movies, 'movieId')\n",
    "    .orderBy(F.desc('rating'))\n",
    "\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>genres</th>\n",
       "      <th>movieTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1196</td>\n",
       "      <td>0</td>\n",
       "      <td>4.985356</td>\n",
       "      <td>Action|Adventure|Drama|Sci-Fi|War</td>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2628</td>\n",
       "      <td>0</td>\n",
       "      <td>4.852185</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace (1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>4.824620</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2927</td>\n",
       "      <td>0</td>\n",
       "      <td>4.718616</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>Brief Encounter (1946)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3793</td>\n",
       "      <td>0</td>\n",
       "      <td>4.713987</td>\n",
       "      <td>Action|Sci-Fi</td>\n",
       "      <td>X-Men (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2116</td>\n",
       "      <td>0</td>\n",
       "      <td>4.704656</td>\n",
       "      <td>Adventure|Animation|Children's|Sci-Fi</td>\n",
       "      <td>Lord of the Rings, The (1978)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1284</td>\n",
       "      <td>0</td>\n",
       "      <td>4.661451</td>\n",
       "      <td>Film-Noir|Mystery</td>\n",
       "      <td>Big Sleep, The (1946)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4.621117</td>\n",
       "      <td>Drama|Sci-Fi</td>\n",
       "      <td>Twelve Monkeys (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3213</td>\n",
       "      <td>0</td>\n",
       "      <td>4.606632</td>\n",
       "      <td>Animation|Children's</td>\n",
       "      <td>Batman: Mask of the Phantasm (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>465</td>\n",
       "      <td>0</td>\n",
       "      <td>4.595791</td>\n",
       "      <td>Action|Drama|War</td>\n",
       "      <td>Heaven &amp; Earth (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1333</td>\n",
       "      <td>0</td>\n",
       "      <td>4.586455</td>\n",
       "      <td>Horror</td>\n",
       "      <td>Birds, The (1963)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>903</td>\n",
       "      <td>0</td>\n",
       "      <td>4.541980</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>Vertigo (1958)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>923</td>\n",
       "      <td>0</td>\n",
       "      <td>4.525115</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Citizen Kane (1941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2745</td>\n",
       "      <td>0</td>\n",
       "      <td>4.518758</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Mission, The (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1527</td>\n",
       "      <td>0</td>\n",
       "      <td>4.504928</td>\n",
       "      <td>Action|Sci-Fi</td>\n",
       "      <td>Fifth Element, The (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1198</td>\n",
       "      <td>0</td>\n",
       "      <td>4.481770</td>\n",
       "      <td>Action|Adventure</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.469234</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>Heat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movieId  userId    rating                                 genres  \\\n",
       "0      1196       0  4.985356      Action|Adventure|Drama|Sci-Fi|War   \n",
       "1      2628       0  4.852185        Action|Adventure|Fantasy|Sci-Fi   \n",
       "2       260       0  4.824620        Action|Adventure|Fantasy|Sci-Fi   \n",
       "3      2927       0  4.718616                          Drama|Romance   \n",
       "4      3793       0  4.713987                          Action|Sci-Fi   \n",
       "5      2116       0  4.704656  Adventure|Animation|Children's|Sci-Fi   \n",
       "6      1284       0  4.661451                      Film-Noir|Mystery   \n",
       "7        32       0  4.621117                           Drama|Sci-Fi   \n",
       "8      3213       0  4.606632                   Animation|Children's   \n",
       "9       465       0  4.595791                       Action|Drama|War   \n",
       "10     1333       0  4.586455                                 Horror   \n",
       "11      903       0  4.541980                       Mystery|Thriller   \n",
       "12      923       0  4.525115                                  Drama   \n",
       "13     2745       0  4.518758                                  Drama   \n",
       "14     1527       0  4.504928                          Action|Sci-Fi   \n",
       "15     1198       0  4.481770                       Action|Adventure   \n",
       "16        6       0  4.469234                  Action|Crime|Thriller   \n",
       "\n",
       "                                           movieTitle  \n",
       "0   Star Wars: Episode V - The Empire Strikes Back...  \n",
       "1    Star Wars: Episode I - The Phantom Menace (1999)  \n",
       "2           Star Wars: Episode IV - A New Hope (1977)  \n",
       "3                              Brief Encounter (1946)  \n",
       "4                                        X-Men (2000)  \n",
       "5                       Lord of the Rings, The (1978)  \n",
       "6                               Big Sleep, The (1946)  \n",
       "7                               Twelve Monkeys (1995)  \n",
       "8                 Batman: Mask of the Phantasm (1993)  \n",
       "9                               Heaven & Earth (1993)  \n",
       "10                                  Birds, The (1963)  \n",
       "11                                     Vertigo (1958)  \n",
       "12                                Citizen Kane (1941)  \n",
       "13                                Mission, The (1986)  \n",
       "14                          Fifth Element, The (1997)  \n",
       "15                     Raiders of the Lost Ark (1981)  \n",
       "16                                        Heat (1995)  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendiendo cómo se realizan las predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entender qué descomposición se ha realizado y cómo se realizan las predicciones. \n",
    "La matriz de ratings tiene tamaño $(6041\\times3706)$ como hemos visto y en el entrenamiento se ha decidido utilizar 100 variables latentes luego la descomposición que hemos realizado es:\n",
    "&nbsp;<br>\n",
    "&nbsp;<br>\n",
    "\n",
    "$$\n",
    "{\\Large\n",
    "M_{(6041\\times 3706)} = U_{(6041\\times 100)}\\;V_{(100 \\times 3706)}\n",
    "}\n",
    "$$\n",
    "\n",
    "¿Dónde están esas matrices calculadas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22387946"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6041 *  3706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "974700"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * (6041 +  3706)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, features: array<float>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel.itemFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, features: array<float>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel.userFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finalModel.itemFactors.first()['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finalModel.userFactors.first()['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel.itemFactors.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6041"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel.userFactors.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto el objeto `finalModel` además contiene varias funciones para hacer las predicciones, pero vamos a hacerlo a mano para entender cómo funciona algebráicamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nueso id de usuario es el 0 así que podemos quedarnos con la fila de la matriz $U$ que hace referencia a nuestro usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.27074966e-01,  1.38208076e-01, -2.64803991e-02,  3.33696641e-02,\n",
       "        3.75877678e-01,  1.97964418e-03,  3.29350948e-01, -6.45460367e-01,\n",
       "        5.07412963e-02,  1.86721161e-01,  1.78169698e-01,  1.32799298e-01,\n",
       "       -1.88942447e-01,  1.98551621e-02, -2.40450785e-01, -9.10611823e-03,\n",
       "       -2.87065029e-01,  1.95335701e-01, -2.04408228e-01, -8.81161690e-02,\n",
       "       -8.37703515e-03,  3.46145667e-02, -1.79549024e-01,  1.17066026e-01,\n",
       "        2.99455255e-01, -1.08999521e-01, -5.09200990e-02,  1.18876822e-01,\n",
       "       -1.41237780e-01, -9.10440758e-02,  2.96517432e-01,  2.66705062e-02,\n",
       "       -1.28219515e-01, -4.31135565e-01, -1.59222141e-01,  2.27298751e-01,\n",
       "        8.62219632e-02, -1.97181344e-01,  1.85575053e-01, -1.23524396e-02,\n",
       "        1.55094895e-04, -6.17765747e-02, -1.72597855e-01,  3.14780861e-01,\n",
       "       -2.43565604e-01, -3.39462698e-01,  2.94025224e-02,  2.02893227e-01,\n",
       "       -1.64375007e-02,  2.98378766e-01, -1.92630947e-01, -1.83136929e-02,\n",
       "       -3.02985613e-03,  2.87626565e-01,  3.29148173e-01, -4.32273269e-01,\n",
       "        3.31974983e-01,  8.49649534e-02,  1.74488738e-01, -1.50004923e-01,\n",
       "        1.96395218e-01, -1.90223485e-01, -3.30667228e-01, -1.42577561e-02,\n",
       "        5.47001898e-01, -2.32799351e-01,  1.13620959e-01, -2.27830559e-01,\n",
       "        7.16812164e-02, -5.18510938e-02,  2.65709788e-01,  2.39425495e-01,\n",
       "       -1.33221462e-01,  4.82757807e-01, -4.98534851e-02, -5.50672770e-01,\n",
       "        1.07009746e-01,  1.08970791e-01, -2.95503121e-02, -1.57762095e-01,\n",
       "        1.72584638e-01, -2.34783575e-01, -1.10982597e-01,  7.94037655e-02,\n",
       "        3.97043675e-01, -6.22259453e-02, -2.92538494e-01, -5.79924360e-02,\n",
       "        3.26545388e-01, -1.74968019e-01, -9.71202925e-02,  1.12092301e-01,\n",
       "       -1.06792212e-01, -1.71565503e-01, -4.78056706e-02,  1.16658360e-01,\n",
       "        5.31322122e-01,  4.75985631e-02,  2.04344258e-01,  4.99191433e-02])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feature = np.array(finalModel.userFactors.filter(\"\"\" id==0 \"\"\").first()['features'])\n",
    "user_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperamos nuestra primera recomendación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>genres</th>\n",
       "      <th>movieTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1196</td>\n",
       "      <td>0</td>\n",
       "      <td>4.985356</td>\n",
       "      <td>Action|Adventure|Drama|Sci-Fi|War</td>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  userId    rating                             genres  \\\n",
       "0     1196       0  4.985356  Action|Adventure|Drama|Sci-Fi|War   \n",
       "\n",
       "                                          movieTitle  \n",
       "0  Star Wars: Episode V - The Empire Strikes Back...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos de la columna $V$ la columna correspondiente con esta película"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25193983,  0.4593589 ,  0.69353467, -0.59827894,  0.17555617,\n",
       "        0.35568225,  0.10605962, -0.7525779 ,  0.09290539, -0.44745201,\n",
       "        0.14659329,  0.59422117, -1.06495166, -0.37317017, -0.16108066,\n",
       "        0.06068132,  0.27428964,  0.42094019,  0.36652872, -0.04606232,\n",
       "        0.14537959, -0.14121681,  0.20360228,  0.19725148,  0.68586254,\n",
       "        0.29007748, -0.05535936,  0.00187748,  0.36029673, -0.12457822,\n",
       "        0.40042466, -0.23747288, -0.20063256, -0.49935016, -0.04984265,\n",
       "        0.19434354, -0.36708063,  0.37541667, -0.027764  ,  0.07531852,\n",
       "        0.67511994, -0.31004584, -0.02863843,  1.03480291,  0.02380848,\n",
       "       -0.30676618,  0.09542111, -0.13920975,  0.04061755,  0.33759603,\n",
       "       -0.0051939 , -0.45956063,  0.00498535,  0.40992159,  0.57044476,\n",
       "       -0.71875125,  0.35103998,  0.00398565,  0.26617759, -0.67313874,\n",
       "        0.25990111, -0.10224196,  0.03150572, -0.39903805,  0.79356968,\n",
       "        0.15292095,  0.50998664, -0.40732798,  0.16901854,  0.18501823,\n",
       "        0.66595334, -0.06932754, -0.19390947,  0.41738266,  0.63737905,\n",
       "       -0.50159031,  0.07014361, -0.36931616,  0.4174085 ,  0.13951617,\n",
       "        0.07749087, -0.77388823, -0.28638572,  0.73604107,  0.16137074,\n",
       "        0.15353461, -0.3710238 , -0.24721776,  1.01041329, -0.45089909,\n",
       "        0.19812301,  0.35598651, -0.14741974, -0.40159398,  0.03893378,\n",
       "        0.7512455 ,  0.2516059 , -0.047834  ,  0.09950322,  0.35877404])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_features = np.array(\n",
    "    finalModel.itemFactors\n",
    "    .filter(F.col('id') == int(recommendations.movieId[0]))\n",
    "    .first()['features']\n",
    ")\n",
    "product_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para terminar, es fácil de comprobar que matemáticamente:\n",
    "$$\n",
    "{\\Large\n",
    "m_{ij} =\\; <u_i, v_j>\n",
    "}\n",
    "$$\n",
    "\n",
    "Es decir, el rating del usuario $i$ y el item $j$ es el producto escalar de la fila  $i$-esima de la matriz $U$ y la columna $j$-esima de la matriz $V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.985357844265989"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(user_feature, product_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos las dos matrices de manera local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para terminar vamos a guardar las dos matrices de manera local para poder usarlas más tarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_factors = (\n",
    "\n",
    "    finalModel\n",
    "    .itemFactors\n",
    "\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_factors.to_json('item_factors.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_factors = (\n",
    "\n",
    "    finalModel\n",
    "    .userFactors\n",
    "\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_factors.to_json('user_factors.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Crear un sistema de recomendaciones para los datos de **last.fm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "# Cargamos las funciones definidas en el archivo funciones_auxiliares.py\n",
    "from funciones_auxiliares import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "\n",
    "    SparkConf()\n",
    "    .setAppName(u\"Sistemas de Recomendación\")\n",
    "    .set(\"spark.executor.memory\", \"4g\")\n",
    "    .set(\"spark.executor.cores\", \"2\")\n",
    "    .set(\"spark.default.parallelism\", \"800\")\n",
    "    .set(\"spark.sql.shuffle.partitions\", \"800\")\n",
    "    .set(\"spark.submit.pyFiles\", \"funciones_auxiliares.py\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "\n",
    "    SparkSession.builder\n",
    "    .config(conf=conf)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "![image](../img/logo_lastfm.png)\n",
    "    \n",
    "</center>\n",
    "\n",
    "http://ocelma.net/MusicRecommendationDataset/lastfm-360K.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://musicbrainz.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000c289a1829a808ac09c00daf10bc3c4e223b\t3bd73256-3905-4f3a-97e2-8b341527f805\tbetty blowtorch\t2137\n",
      "00000c289a1829a808ac09c00daf10bc3c4e223b\tf2fb0ff0-5679-42ec-a55c-15109ce6e320\tdie Ärzte\t1099\n",
      "00000c289a1829a808ac09c00daf10bc3c4e223b\tb3ae82c2-e60b-4551-a76d-6620f1b456aa\tmelissa etheridge\t897\n",
      "00000c289a1829a808ac09c00daf10bc3c4e223b\t3d6bbeb7-f90e-4d10-b440-e153c0d10b53\telvenking\t717\n",
      "00000c289a1829a808ac09c00daf10bc3c4e223b\tbbd2ffd7-17f4-4506-8572-c1ea58c3f9a8\tjuliette & the licks\t706\n",
      "00000c289a1829a808ac09c00daf10bc3c4e223b\t8bfac288-ccc5-448d-9573-c33ea2aa5c30\tred hot chili peppers\t691\n",
      "00000c289a1829a808ac09c00daf10bc3c4e223b\t6531c8b1-76ea-4141-b270-eb1ac5b41375\tmagica\t545\n",
      "00000c289a1829a808ac09c00daf10bc3c4e223b\t21f3573f-10cf-44b3-aeaa-26cccd8448b5\tthe black dahlia murder\t507\n",
      "00000c289a1829a808ac09c00daf10bc3c4e223b\tc5db90c4-580d-4f33-b364-fbaa5a3a58b5\tthe murmurs\t424\n",
      "00000c289a1829a808ac09c00daf10bc3c4e223b\t0639533a-0402-40ba-b6e0-18b067198b73\tlunachicks\t403\n",
      "text: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -text /datos/lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "esquema = T.StructType([\n",
    "\n",
    "    T.StructField('user_id',T.StringType(),True),\n",
    "    T.StructField('artist_id',T.StringType(),True),\n",
    "    T.StructField('artist_name',T.StringType(),True),\n",
    "    T.StructField('plays',T.DoubleType(),True)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "plays = (\n",
    "\n",
    "    spark.read\n",
    "    .csv('/datos/lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv', schema=esquema, sep='\\t')\n",
    "    .na.drop()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------+\n",
      "|             user_id|           artist_id|         artist_name| plays|\n",
      "+--------------------+--------------------+--------------------+------+\n",
      "|00000c289a1829a80...|3bd73256-3905-4f3...|     betty blowtorch|2137.0|\n",
      "|00000c289a1829a80...|f2fb0ff0-5679-42e...|           die Ärzte|1099.0|\n",
      "|00000c289a1829a80...|b3ae82c2-e60b-455...|   melissa etheridge| 897.0|\n",
      "|00000c289a1829a80...|3d6bbeb7-f90e-4d1...|           elvenking| 717.0|\n",
      "|00000c289a1829a80...|bbd2ffd7-17f4-450...|juliette & the licks| 706.0|\n",
      "|00000c289a1829a80...|8bfac288-ccc5-448...|red hot chili pep...| 691.0|\n",
      "|00000c289a1829a80...|6531c8b1-76ea-414...|              magica| 545.0|\n",
      "|00000c289a1829a80...|21f3573f-10cf-44b...|the black dahlia ...| 507.0|\n",
      "|00000c289a1829a80...|c5db90c4-580d-4f3...|         the murmurs| 424.0|\n",
      "|00000c289a1829a80...|0639533a-0402-40b...|          lunachicks| 403.0|\n",
      "|00000c289a1829a80...|a342964d-ca53-4e5...|    walls of jericho| 393.0|\n",
      "|00000c289a1829a80...|f779ed95-66c8-449...|      letzte instanz| 387.0|\n",
      "|00000c289a1829a80...|7b885d42-3c41-4f4...|           goldfrapp| 361.0|\n",
      "|00000c289a1829a80...|e000d76b-afff-428...|          horrorpops| 358.0|\n",
      "|00000c289a1829a80...|adf334c2-9186-48c...|        the butchies| 329.0|\n",
      "|00000c289a1829a80...|7e870dd5-2667-454...|       jack off jill| 316.0|\n",
      "|00000c289a1829a80...|41593aa1-dda6-4a5...|    babes in toyland| 310.0|\n",
      "|00000c289a1829a80...|e8374874-4178-486...|    dropkick murphys| 302.0|\n",
      "|00000c289a1829a80...|295a3ae3-9e81-4cf...|       all:my:faults| 288.0|\n",
      "|00000c289a1829a80...|2d67239c-aa40-4ad...|            le tigre| 281.0|\n",
      "+--------------------+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plays.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
